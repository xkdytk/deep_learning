{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Cut Mix**"
      ],
      "metadata": {
        "id": "stt3-yWKmoBL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSUTnCjemc3k"
      },
      "outputs": [],
      "source": [
        "def rand_bbox(W, H, lam):\n",
        "    cut_rat = torch.sqrt(1.0 - lam)\n",
        "    cut_w = (W * cut_rat).type(torch.long)\n",
        "    cut_h = (H * cut_rat).type(torch.long)\n",
        "    # uniform\n",
        "    cx = torch.randint(W, (1,)).to(device)\n",
        "    cy = torch.randint(H, (1,)).to(device)\n",
        "    x1 = torch.clamp(cx - cut_w // 2, 0, W)\n",
        "    y1 = torch.clamp(cy - cut_h // 2, 0, H)\n",
        "    x2 = torch.clamp(cx + cut_w // 2, 0, W)\n",
        "    y2 = torch.clamp(cy + cut_h // 2, 0, H)\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0, p=0.5):\n",
        "    if np.random.random() > p:\n",
        "        return x, y, torch.zeros_like(y), 1.0\n",
        "    W, H = x.size(2), x.size(3)\n",
        "    shuffle = torch.randperm(x.size(0)).to(device)\n",
        "    cutmix_x = x\n",
        "\n",
        "    lam = torch.distributions.beta.Beta(alpha, alpha).sample().to(device)\n",
        "\n",
        "    x1, y1, x2, y2 = rand_bbox(W, H, lam)\n",
        "    cutmix_x[:, :, x1:x2, y1:y2] = x[shuffle, :, x1:x2, y1:y2]\n",
        "    # Adjust lambda to match pixel ratio\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / float(W * H)).item()\n",
        "    y_a, y_b = y, y[shuffle]\n",
        "    return cutmix_x, y_a, y_b, lam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Label Smooth Loss**"
      ],
      "metadata": {
        "id": "SBg1Tl-0m2YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    if len(targets.shape) == 1:\n",
        "        return F.cross_entropy(outputs, targets)\n",
        "    else:\n",
        "        return torch.mean(torch.sum(-targets * F.log_softmax(outputs, dim=1), dim=1))\n",
        "\n",
        "def label_smooth_loss_fn(outputs, targets, epsilon=0.1):\n",
        "    onehot = F.one_hot(targets, 1000).float().to(device)\n",
        "    targets = (1 - epsilon) * onehot + torch.ones(onehot.shape).to(device) * epsilon / 1000\n",
        "    return loss_fn(outputs, targets)"
      ],
      "metadata": {
        "id": "q_2pEM8omuq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train**"
      ],
      "metadata": {
        "id": "5hLoEy3xotMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = torch.cuda.amp.GradScaler()\n",
        "optimizer = optim.Adam(Model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n",
        "loss=label_smooth_loss_fn\n",
        "\n",
        "Model.train()\n",
        "\n",
        "Model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS) :\n",
        "  loss_val_sum=0\n",
        "  for imgs, labels in train_loader:\n",
        "    # Cut mix P=0.5\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "    imgs, labels_a, labels_b, lam = cutmix_data(imgs, labels)\n",
        "\n",
        "    # optimizer.zero_grad()\n",
        "    for param in Model.parameters():\n",
        "      param.grad = None\n",
        "    model_pred=Model(imgs)\n",
        "\n",
        "    # Label Smoothing + Cutmix\n",
        "    loss_out = lam * loss(model_pred, labels_a) + (1 - lam) * loss(model_pred, labels_b)\n",
        "\n",
        "    scaler.scale(loss_out).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    loss_val_sum+=loss_out\n",
        "    visual_loss_sum+=normal_loss_out\n",
        "\n",
        "  loss_val_avg=loss_val_sum/len(train_loader)\n",
        "\n",
        "  scheduler.step(loss_val_avg)"
      ],
      "metadata": {
        "id": "2H5dtdNtosoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}